<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on NetKet</title><link>/</link><description>Recent content in Home on NetKet</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Copyright 2019-2022, The Netket authors - All rights reserved.</copyright><lastBuildDate>Tue, 01 Feb 2022 17:48:04 +0100</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Get Involved</title><link>/get_involved/</link><pubDate>Tue, 01 Feb 2022 18:02:27 +0100</pubDate><guid>/get_involved/</guid><description>Getting In Touch with the community Users and developers of NetKet hang out in the following places:
GitHub Discussions: we encourage users who have questions about NetKet and Neural Quantum States in general to start a discussion thread. We like them because they are not ephemeral, they are indexed by search engines, and if you get an answer it might benefit other people in the future. GitHub Issues: if you believe you have found a bug, or have a feature request or just want to discuss something to implement in NetKet, we encourage you to start an Issue on GitHub!</description></item><item><title>Citing</title><link>/cite/</link><pubDate>Tue, 01 Feb 2022 18:02:27 +0100</pubDate><guid>/cite/</guid><description/></item><item><title>Fermionic Neural Quantum States Workshop - Paris, Dec 1-2, 2025</title><link>/posts/05-fermionic-nqs-workshop/</link><pubDate>Mon, 15 Sep 2025 00:00:00 +0000</pubDate><guid>/posts/05-fermionic-nqs-workshop/</guid><description>We are excited to announce the Fermionic Neural Quantum States: Recent Developments workshop, taking place December 1-2, 2025, at Collège de France in Paris.
This focused 2-day workshop brings together leading practitioners in the field to discuss recent progress and promising directions in fermionic neural quantum states, covering applications in electronic structure, hadronic physics, and related areas.
Workshop Details When: December 1-2, 2025 Where: Collège de France, Paris (11 Place Marcelin Berthelot, 75005 Paris) Format: ~12 invited talks + poster session + round-table discussions Participants: ~50 expected attendees</description></item><item><title>Looking elsewhere: improving variational Monte Carlo gradients by importance sampling</title><link>/papers/misery-importance-sampling/</link><pubDate>Tue, 15 Jul 2025 00:00:00 +0000</pubDate><guid>/papers/misery-importance-sampling/</guid><description>The paper discusses improving neural-network quantum states (NQS) training via Variational Monte Carlo (VMC) methods. The authors propose a systematic strategy to tackle sampling issues by means of adaptively tuned importance sampling that can reduce the computational cost of vanilla VMC considerably, up to a factor of 100x when targeting highly peaked quantum chemistry wavefunctions.</description></item><item><title>Variational subspace methods and application to improving variational Monte Carlo dynamics</title><link>/papers/kahn-variational-subspace/</link><pubDate>Tue, 15 Jul 2025 00:00:00 +0000</pubDate><guid>/papers/kahn-variational-subspace/</guid><description>We present a formalism that allows for the direct manipulation and optimization of subspaces, circumventing the need to optimize individual states when using subspace methods. Using the determinant state mapping, we can naturally extend notions such as distance and energy to subspaces, as well as Monte Carlo estimators, recovering the excited states estimation method proposed by Pfau et al. As a practical application, we then introduce Bridge, a method that improves the performance of variational dynamics by extracting linear combinations of variational time-evolved states.</description></item><item><title>Neural Projected Quantum Dynamics: a systematic study</title><link>/papers/gravina-pvqd-systematic/</link><pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate><guid>/papers/gravina-pvqd-systematic/</guid><description>We address the challenge of simulating unitary quantum dynamics in large systems using Neural Quantum States, focusing on overcoming the computational instabilities and high cost of existing methods. This work offers a comprehensive formalization of the projected time-dependent Variational Monte Carlo (p-tVMC) method by thoroughly analyzing its two essential components: stochastic infidelity minimization and discretization of the unitary evolution. We investigate neural infidelity minimization using natural gradient descent strategies, identifying the most stable stochastic estimators and introducing adaptive regularization strategies that eliminate the need for manual adjustment of the hyperparameter along the dynamics.</description></item><item><title>Simple Fermionic backflow states via a systematically improvable tensor decomposition</title><link>/papers/bortone-gpsket-backflow/</link><pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate><guid>/papers/bortone-gpsket-backflow/</guid><description>We present an effective ansatz for the wave function of correlated electrons that brings closer the fields of machine learning parameterizations and tensor rank decompositions. We consider a CANDECOMP/PARAFAC (CP) tensor factorization of a general backflow transformation in second quantization for a simple, compact and systematically improvable Fermionic state. This directly encodes N-body correlations without the ordering dependence of other tensor decompositions. We consider and explicitly demonstrate various controllable truncations, in the rank and range of the backflow correlations or magnitude of local energy contributions, in order to systematically affect scaling reductions to O(N³)-O(N⁴).</description></item><item><title>Empirical sample complexity of neural network mixed state reconstruction</title><link>/papers/zhao-sample-complexity-ndm/</link><pubDate>Thu, 23 May 2024 00:00:00 +0000</pubDate><guid>/papers/zhao-sample-complexity-ndm/</guid><description>Quantum state reconstruction using Neural Quantum States has been proposed as a viable tool to reduce quantum shot complexity in practical applications, and its advantage over competing techniques has been shown in numerical experiments focusing mainly on the noiseless case. In this work, we numerically investigate the performance of different quantum state reconstruction techniques for mixed states: the finite-temperature Ising model. We show how to systematically reduce the quantum resource requirement of the algorithms by applying variance reduction techniques.</description></item><item><title>Efficiency of neural quantum states in light of the quantum geometric tensor</title><link>/papers/dash-qgt/</link><pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate><guid>/papers/dash-qgt/</guid><description>Neural quantum state (NQS) ansätze have shown promise in variational Monte Carlo algorithms by their theoretical capability of representing any quantum state. However, the reason behind the practical improvement in their performance with an increase in the number of parameters is not fully understood. In this work, we systematically study the efficiency of restricted Boltzmann Machines (RBMs) to repre- sent the ground states in different phases of the spin-1 bilinear-biquadratic model, as the hidden layer density α increases.</description></item><item><title>Impact of conditional modelling for a universal autoregressive quantum state</title><link>/papers/bortone-gpsket-autoreg/</link><pubDate>Mon, 15 Jan 2024 00:00:00 +0000</pubDate><guid>/papers/bortone-gpsket-autoreg/</guid><description>We present a generalized framework to adapt universal quantum state approximators, enabling them to satisfy rigorous normalization and autoregressive properties. We also introduce filters as analogues to convolutional layers in neural networks to incorporate translationally symmetrized correlations in arbitrary quantum states. By applying this framework to the Gaussian process state, we enforce autoregressive and/or filter properties, analyzing the impact of the resulting inductive biases on variational flexibility, symmetries, and conserved quantities.</description></item><item><title>A simple linear algebra identity to optimize large-scale neural network quantum states</title><link>/papers/rende-linearalgebrasimple/</link><pubDate>Mon, 09 Oct 2023 00:00:00 +0000</pubDate><guid>/papers/rende-linearalgebrasimple/</guid><description>Neural-network architectures have been increasingly used to represent quantum many-body wave functions. These networks require a large number of variational parameters and are challenging to optimize using traditional methods, as gradient descent. Stochastic reconfiguration (SR) has been effective with a limited number of parameters, but becomes impractical beyond a few thousand parameters. Here, we leverage a simple linear algebra identity to show that SR can be employed even in the deep learning scenario.</description></item><item><title>Variational Embeddings for Many Body Quantum Systems</title><link>/papers/barison-embedding/</link><pubDate>Fri, 15 Sep 2023 00:00:00 +0000</pubDate><guid>/papers/barison-embedding/</guid><description>We propose a variational scheme to represent composite quantum systems using multiple param- eterized functions of varying accuracies on both classical and quantum hardware. The approach follows the variational principle over the entire system, and is naturally suited for scenarios where an accurate description is only needed in a smaller subspace. We show how to include quantum devices as high-accuracy solvers on these correlated degrees of freedom, while handling the remain- ing contributions with a classical device.</description></item><item><title>Unbiasing time-dependent Variational Monte Carlo by projected quantum evolution</title><link>/papers/sinibaldi-unbiasing/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>/papers/sinibaldi-unbiasing/</guid><description>We analyze the accuracy and sample complexity of variational Monte Carlo approaches to simulate the dynamics of many-body quantum systems classically. By systematically studying the relevant stochastic estimators, we are able to: (i) prove that the most used scheme, the time-dependent Variational Monte Carlo (tVMC), is affected by a systematic statistical bias or exponential sample complexity when the wave function contains some (possibly approximate) zeros, an important case for fermionic systems and quantum information protocols; (ii) show that a different scheme based on the solution of an optimization problem at each time step is free from such problems; (iii) improve the sample complexity of this latter approach by several orders of magnitude with respect to previous proofs of concept.</description></item><item><title>High-accuracy variational Monte Carlo for frustrated magnets with deep neural networks</title><link>/papers/roth-highaccuracyfrustratedmagnets/</link><pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate><guid>/papers/roth-highaccuracyfrustratedmagnets/</guid><description>We show that neural quantum states based on very deep (4–16-layered) neural networks can outperform state-of-the-art variational approaches on highly frustrated quantum magnets, including quantum-spin-liquid candidates. We focus on group convolutional neural networks that allow us to efficiently impose space-group symmetries on our ansätze. We achieve state-of-the-art ground-state energies for the 𝐽1−𝐽2 Heisenberg models on the square and triangular lattices, in both ordered and spin-liquid phases, and discuss ways to access low-lying excited states in nontrivial symmetry sectors.</description></item><item><title>NetKet 3: Machine Learning Toolbox for Many-Body Quantum Systems</title><link>/papers/vicentini-netket3/</link><pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate><guid>/papers/vicentini-netket3/</guid><description>We introduce version 3 of NetKet, the machine learning toolbox for many-body quantum physics. NetKet is built around neural-network quantum states and provides efficient algorithms for their evaluation and optimization. This new version is built on top of JAX, a differentiable programming and accelerated linear algebra framework for the Python programming language. The most significant new feature is the possibility to define arbitrary neural network ansätze in pure Python code using the concise notation of machine-learning frameworks, which allows for just-in-time compilation as well as the implicit generation of gradients thanks to automatic differentiation.</description></item><item><title>Positive-definite parametrization of mixed quantum states with deep neural networks</title><link>/papers/vicentini-positive-def-ndm/</link><pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate><guid>/papers/vicentini-positive-def-ndm/</guid><description>We introduce the Gram-Hadamard Density Operator (GHDO), a new deep neural-network architecture that can encode positive semi-definite density operators of exponential rank with polynomial resources. We then show how to embed an autoregressive structure in the GHDO to allow direct sampling of the probability distribution. These properties are especially important when representing and variationally optimizing the mixed quantum state of a system interacting with an environment. Finally, we benchmark this architecture by simulating the steady state of the dissipative transverse-field Ising model.</description></item><item><title>UnitaryHack: Win bounties with NetKet</title><link>/posts/3-unitaryhack/</link><pubDate>Sun, 01 May 2022 10:23:16 +0100</pubDate><guid>/posts/3-unitaryhack/</guid><description>NetKet is participating in the 2022 edition of UnitaryHack, kindly sponsored by the quantum non-profit Unitary Fund.
The hackathon will run for two weeks, from Friday, June 3 to Friday, June 17. During the hackathon, several high-profile quantum software projects are each proposing several tasks for which Unitary Fund will provide a bounty to the participant completing the task.
NetKet is participating with 4 bounties to this hackathon, which are worth US$ 300 in total.</description></item><item><title>NetKet-friendly Summer School in Toulouse</title><link>/posts/02-toulouse/</link><pubDate>Mon, 14 Feb 2022 10:23:16 +0100</pubDate><guid>/posts/02-toulouse/</guid><description>We are glad to advertise that our dear colleagues in Toulouse are organising a Summer school in April on Machine Learning techniques for Quantum Many-Body Physics. The school will feature several lectures and tutorials on NetKet.
Below you can find the original announcement.
Announcement Toulouse School on Machine Learning for Quantum Many-Body Physics
that will take place in Toulouse, France (4th-8th April 2022).
The school will take place in hybrid format (with both online and onsite students and lecturers).</description></item><item><title>Get Started</title><link>/get_started/</link><pubDate>Tue, 01 Feb 2022 18:02:27 +0100</pubDate><guid>/get_started/</guid><description>window.location.href = "https://netket.readthedocs.io"; Get Started with NetKet For installation instructions, tutorials, and comprehensive documentation, please visit our official documentation at netket.readthedocs.io.
You will be redirected automatically.</description></item><item><title>NetKet 3 ❤️ Jax</title><link>/posts/01-welcome/</link><pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate><guid>/posts/01-welcome/</guid><description>18 months in development, NetKet 3.0 indicates a major new step for the NetKet project. NetKet has been totally rewritten in Python and is now a Jax-based library. This guarantees outstanding performance while allowing researchers to exploit machine-learning frameworks to define advanced Neural-Networks.
GPUs and Google’s TPUs are now supported too!
Update now and try the new examples!</description></item></channel></rss>